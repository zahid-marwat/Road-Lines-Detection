{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd777c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec976cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    1: \"LONGITUDINAL\",\n",
    "    2: \"TRANSVERSE\",\n",
    "    3: \"PATCHING\",\n",
    "    4: \"BLOCK\",\n",
    "    5: \"POTHOLE\"\n",
    "}\n",
    "\n",
    "for i in range(len(boxes)):\n",
    "    if scores[i] >= score_threshold:\n",
    "        box = boxes[i].cpu().numpy()\n",
    "        label_id = labels[i].item()\n",
    "        label_name = class_map.get(label_id, str(label_id))\n",
    "        ax.add_patch(plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
    "                                   fill=False, color='red', linewidth=2))\n",
    "        ax.text(box[0], box[1], f'{label_name}:{scores[i]:.2f}', \n",
    "                fontsize=12, color='yellow', bbox=dict(facecolor='red', alpha=0.5))\n",
    "        mask = masks[i, 0].cpu().numpy()\n",
    "        ax.imshow(mask, alpha=0.5, cmap='jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649673f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Load the Mask R-CNN model architecture with the correct number of classes\n",
    "model = maskrcnn_resnet50_fpn(pretrained=False, num_classes=6)\n",
    "model.load_state_dict(torch.load(\"maskrcnn_resnet50_trained_1.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Load and preprocess an image\n",
    "image = Image.open(\"3.jpg\").convert(\"RGB\")\n",
    "img_tensor = F.to_tensor(image)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    prediction = model([img_tensor])\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Get prediction results\n",
    "    pred = prediction[0]\n",
    "    boxes = pred['boxes']\n",
    "    labels = pred['labels']\n",
    "    scores = pred['scores']\n",
    "    masks = pred['masks']\n",
    "\n",
    "    # Set a score threshold for visualization\n",
    "    score_threshold = 0.5\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] >= score_threshold:\n",
    "            label_id = labels[i].item()\n",
    "            label_name = class_map.get(label_id, str(label_id))\n",
    "            print(label_name)\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] >= score_threshold:\n",
    "            box = boxes[i].cpu().numpy()\n",
    "            label_id = labels[i].item()\n",
    "            label_name = class_map.get(label_id, str(label_id))\n",
    "            ax.add_patch(plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
    "                                       fill=False, color='red', linewidth=2))\n",
    "            ax.text(box[0], box[1], f'{label_name}:{scores[i]:.2f}', \n",
    "                    fontsize=12, color='yellow', bbox=dict(facecolor='red', alpha=0.5))\n",
    "            # Draw mask if available\n",
    "            mask = masks[i, 0].cpu().numpy()\n",
    "            ax.imshow(mask, alpha=0.5, cmap='jet')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test:\n",
    "\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from torchvision.ops import nms\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a color map for each class (R, G, B)\n",
    "class_colors = {\n",
    "    1: (1.0, 0.0, 0.0),   # LONGITUDINAL - Red\n",
    "    2: (0.0, 1.0, 0.0),   # TRANSVERSE - Green\n",
    "    3: (0.0, 0.0, 1.0),   # PATCHING - Blue\n",
    "    4: (1.0, 1.0, 0.0),   # BLOCK - Yellow\n",
    "    5: (1.0, 0.0, 1.0),   # POTHOLE - Magenta\n",
    "}\n",
    "\n",
    "# Load the Mask R-CNN model architecture with the correct number of classes\n",
    "model = maskrcnn_resnet50_fpn(pretrained=False, num_classes=6)\n",
    "model.load_state_dict(torch.load(\"maskrcnn_resnet50_trained_1.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# List of image file paths\n",
    "image_dir = \"data/coco/split/test\"  # replace with your image directory\n",
    "img_list = os.listdir(image_dir)\n",
    "image_files = [os.path.join(image_dir, img) for img in img_list if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "output_dir = \"data/coco/split/detected_frames2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "imagecounter = 0\n",
    "for img_path in image_files:\n",
    "    # if imagecounter > 3:     break\n",
    "    imagecounter += 1\n",
    "    print(f\"Processing image {imagecounter}/{len(image_files)}: {img_path}\")\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = F.to_tensor(image)\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img_tensor])\n",
    "        pred = prediction[0]\n",
    "        boxes = pred['boxes']\n",
    "        labels = pred['labels']\n",
    "        scores = pred['scores']\n",
    "        masks = pred['masks']\n",
    "        # Apply Non-Maximum Suppression (NMS)\n",
    "\n",
    "        # Convert boxes and scores to CPU and numpy for NMS\n",
    "        boxes_cpu = boxes.cpu()\n",
    "        scores_cpu = scores.cpu()\n",
    "\n",
    "        # Perform NMS\n",
    "        keep_indices = nms(boxes_cpu, scores_cpu, iou_threshold=0.)\n",
    "\n",
    "        # Filter predictions using NMS indices\n",
    "        boxes = boxes[keep_indices]\n",
    "        labels = labels[keep_indices]\n",
    "        scores = scores[keep_indices]\n",
    "        masks = masks[keep_indices]\n",
    "\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(image)\n",
    "        ax = plt.gca()\n",
    "        # Define class_map if not already defined\n",
    "        class_map = {\n",
    "            1: \"LONGITUDINAL\",\n",
    "            2: \"TRANSVERSE\",\n",
    "            3: \"PATCHING\",\n",
    "            4: \"BLOCK\",\n",
    "            5: \"POTHOLE\"\n",
    "        }\n",
    "\n",
    "        shapes = []\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] >= score_threshold:\n",
    "                box = boxes[i].cpu().numpy()\n",
    "                label_id = labels[i].item()\n",
    "                label_name = class_map.get(label_id, str(label_id))\n",
    "                color = class_colors.get(label_id, (1.0, 1.0, 1.0))  # default white\n",
    "                ax.text(\n",
    "                    box[0], box[1], f'{label_name}:{scores[i]:.2f}',\n",
    "                    fontsize=12, color='yellow'\n",
    "                )\n",
    "\n",
    "                mask = masks[i, 0].cpu().numpy()\n",
    "                mask_rgba = np.zeros((*mask.shape, 4), dtype=np.float32)\n",
    "                mask_rgba[..., 0] = color[0]\n",
    "                mask_rgba[..., 1] = color[1]\n",
    "                mask_rgba[..., 2] = color[2]\n",
    "                mask_rgba[..., 3] = mask * 0.5\n",
    "\n",
    "                ax.imshow(mask_rgba, interpolation='none')\n",
    "\n",
    "                contour_mask = (mask > 0.5).astype(np.uint8) * 255\n",
    "                contours, _ = cv2.findContours(contour_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for contour in contours:\n",
    "                    contour = contour.squeeze()\n",
    "                    if contour.ndim == 2 and contour.shape[0] > 2:\n",
    "                        ax.plot(contour[:, 0], contour[:, 1], color=color, linewidth=2)\n",
    "                        points = contour.tolist()\n",
    "                        distress_coverage = int(np.sum(contour_mask > 0))\n",
    "                        shapes.append({\n",
    "                            \"label\": label_name,\n",
    "                            \"points\": points,\n",
    "                            \"group_id\": None,\n",
    "                            \"shape_type\": \"polygon\",\n",
    "                            \"flags\": {},\n",
    "                            \"distress_coverage\": distress_coverage\n",
    "                        })\n",
    "\n",
    "        annotation = {\n",
    "            \"version\": \"5.0.1\",\n",
    "            \"flags\": {},\n",
    "            \"shapes\": shapes,\n",
    "            \"imagePath\": os.path.basename(img_path),\n",
    "            \"imageData\": None,\n",
    "            \"imageHeight\": image.height,\n",
    "            \"imageWidth\": image.width\n",
    "        }\n",
    "                \n",
    "        # Save annotation as JSON in the output directory\n",
    "        json_path = os.path.splitext(os.path.join(output_dir, os.path.basename(img_path)))[0] + \".json\"\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump(annotation, f, indent=2)\n",
    "        # Encode the image as base64 and add to annotation\n",
    "        buffer = BytesIO()\n",
    "        image.save(buffer, format=\"JPEG\")\n",
    "        encoded_image = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "        annotation[\"imageData\"] = encoded_image\n",
    "\n",
    "        # Save annotation with imageData included\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump(annotation, f, indent=2)\n",
    "        \n",
    "\n",
    "\n",
    "        plt.axis('off')\n",
    "        output_path = os.path.join(output_dir, os.path.basename(img_path))\n",
    "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
