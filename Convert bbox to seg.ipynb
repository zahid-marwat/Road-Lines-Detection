{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def coco_to_yolo_segmentation(coco_json_path, output_dir):\n",
    "    # Load COCO JSON\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Prepare a dictionary for image dimensions\n",
    "    image_dimensions = {img['id']: (img['width'], img['height']) for img in coco_data['images']}\n",
    "\n",
    "    # Iterate through annotations\n",
    "    for annotation in coco_data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        category_id = annotation['category_id']\n",
    "        segmentation = annotation['segmentation']\n",
    "        bbox = annotation['bbox']\n",
    "\n",
    "        # Get image dimensions\n",
    "        width, height = image_dimensions[image_id]\n",
    "\n",
    "        # Normalize bbox (x_center, y_center, width, height)\n",
    "        x_min, y_min, box_width, box_height = bbox\n",
    "        x_center = (x_min + box_width / 2) / width\n",
    "        y_center = (y_min + box_height / 2) / height\n",
    "        box_width /= width\n",
    "        box_height /= height\n",
    "\n",
    "        # Normalize segmentation points\n",
    "        normalized_segmentation = []\n",
    "        for seg in segmentation:\n",
    "            normalized_segmentation.extend([seg[i] / width if i % 2 == 0 else seg[i] / height for i in range(len(seg))])\n",
    "\n",
    "        # Combine class, bbox, and segmentation points\n",
    "        yolo_format = [category_id, x_center, y_center, box_width, box_height] + normalized_segmentation\n",
    "\n",
    "        # Save to YOLO format file\n",
    "        output_file = os.path.join(output_dir, f\"{image_id:06d}.txt\")\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write(\" \".join(map(str, yolo_format)) + \"\\n\")\n",
    "\n",
    "    print(f\"Conversion completed. YOLO files saved in {output_dir}\")\n",
    "\n",
    "# Example usage\n",
    "coco_json_path = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Raw\\labels\\__1JSTPR_S04_2024-08-21-01h24m55s544_crop_0.json' # Path to your COCO JSON file\n",
    "output_dir = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'         # Directory to save YOLO segmentation labels\n",
    "coco_to_yolo_segmentation(coco_json_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.converter import convert_coco\n",
    "\n",
    "convert_coco(labels_dir=r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Raw\\labels', use_segments=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# load json and save directory for labels train/val/test\n",
    "coco_file = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Raw\\labels\\__1JSTPR_S04_2024-08-21-01h24m55s544_crop_0.json'\n",
    "save_folder = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'\n",
    "\n",
    "\n",
    "#source of all the images and destination folder for train/test/val\n",
    "source_path = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Raw\\labels'\n",
    "destination_path = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'\n",
    "\n",
    "\n",
    "# Use os.listdir() to get a list of filenames in the folder\n",
    "file_names = os.listdir(source_path)\n",
    "\n",
    "with open(coco_file) as f:\n",
    "    coco = json.load(f)\n",
    "print(coco.keys())\n",
    "images = coco['images']\n",
    "annotations = coco['annotations'] \n",
    "categories = {cat['id']: cat['name'] for cat in coco['categories']}\n",
    "\n",
    "#os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "for ann in annotations:\n",
    "    image = next(img for img in images if (img['id'] == ann['image_id']))\n",
    "    if (image[\"file_name\"] not in file_names):\n",
    "        continue\n",
    "    #print(f\"image in annotations =   {type(image['id'])}\")\n",
    "    width, height = image['width'], image['height']\n",
    "    x_center = (ann['bbox'][0] + ann['bbox'][2] / 2) / width\n",
    "    y_center = (ann['bbox'][1] + ann['bbox'][3] / 2) / height\n",
    "    bbox_width = ann['bbox'][2] / width\n",
    "    bbox_height = ann['bbox'][3] / height\n",
    "    category_id = ann['category_id']\n",
    "    image_id = ann['image_id']\n",
    "\n",
    "    filename = image['file_name']\n",
    "    label_filename = filename.split('.jpg')[0]\n",
    "    label_path = os.path.join(save_folder, f'{label_filename}.txt')\n",
    "    with open(label_path, 'a') as f:\n",
    "\n",
    "        segmentation_points_list = []\n",
    "        for segmentation in ann['segmentation']:\n",
    "            # Check if any element in segmentation is a string\n",
    "            if any(isinstance(point, str) for point in segmentation):\n",
    "                continue  # Skip this segmentation if it contains strings\n",
    "\n",
    "            segmentation_points = [str(float(point) / width) for point in segmentation]\n",
    "            segmentation_points_list.append(' '.join(segmentation_points))\n",
    "            segmentation_points_string = ' '.join(segmentation_points_list)\n",
    "            line = '{} {}\\n'.format(categories, segmentation_points_string)\n",
    "            f.write(line)\n",
    "            segmentation_points_list.clear()\n",
    "    image_source = source_path + f'/{image[\"file_name\"]}'\n",
    "    shutil.copy(image_source, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Directory containing JSON files and save directory for labels train/val/test\n",
    "json_folder = r'C:\\Users\\fbpza\\Desktop\\pci_SEG dATA\\mUAVIA\\New PCI segmentations'\n",
    "save_folder = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'\n",
    "\n",
    "# Source of all the images and destination folder for train/test/val\n",
    "source_path = r'C:\\Users\\fbpza\\Desktop\\pci_SEG dATA\\mUAVIA\\New PCI segmentations'\n",
    "destination_path = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'\n",
    "\n",
    "# Use os.listdir() to get a list of filenames in the folder\n",
    "file_names = os.listdir(source_path)\n",
    "\n",
    "# Create save folder if it doesn't exist\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over all JSON files in the json_folder\n",
    "for json_file in os.listdir(json_folder):\n",
    "    if json_file.endswith('.json'):\n",
    "        json_path = os.path.join(json_folder, json_file)\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        shapes = data['shapes']\n",
    "        image_path = data['imagePath']\n",
    "        image_file_name = os.path.basename(image_path)\n",
    "\n",
    "        if image_file_name not in file_names:\n",
    "            continue\n",
    "\n",
    "        # Assuming you have width and height information in the JSON data\n",
    "        width = data['imageWidth']\n",
    "        height = data['imageHeight']\n",
    "\n",
    "        for shape in shapes:\n",
    "            label = shape['label'].split('_')[0]\n",
    "            points = shape['points']\n",
    "\n",
    "            segmentation_points_list = []\n",
    "            for point in points:\n",
    "                x, y = point\n",
    "                # Normalize the coordinates\n",
    "                normalized_x = x / width\n",
    "                normalized_y = y / height\n",
    "                segmentation_points_list.append(f\"{normalized_x} {normalized_y}\")\n",
    "\n",
    "            segmentation_points_string = ' '.join(segmentation_points_list)\n",
    "            label_filename = image_file_name.split('.jpg')[0]\n",
    "            label_path = os.path.join(save_folder, f'{label_filename}.txt')\n",
    "            with open(label_path, 'a') as f:\n",
    "                line = f'{label} {segmentation_points_string}\\n'\n",
    "                f.write(line)\n",
    "\n",
    "        image_source = os.path.join(source_path, image_file_name)\n",
    "        shutil.copy(image_source, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the annotation files\n",
    "annotation_dir = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'\n",
    "output_dir = r'C:\\Users\\fbpza\\Desktop\\Road-Lines-Detection\\Data\\PCI_Final\\segmentation'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List all annotation files in the directory\n",
    "annotation_files = [f for f in os.listdir(annotation_dir) if f.endswith('.txt')]\n",
    "\n",
    "# Dictionary for class ID replacement\n",
    "class_id_dict = {\n",
    "    'ALLIGATOR': '9',\n",
    "    'BLOCK': '1',\n",
    "    'LONGITUDINAL': '2',\n",
    "    'PATCHING': '6',\n",
    "    'POTHOLE': '5',\n",
    "    'RAVELING': '10',\n",
    "    'RAVELING.': '4',\n",
    "    'TRANSVERSE': '3',\n",
    "    'WEATHERING': '7'\n",
    "}\n",
    "\n",
    "# Function to convert a single annotation line\n",
    "def convert_annotation_line(line):\n",
    "    parts = line.strip().split()\n",
    "    class_key = parts[0].split('_')[1]  # Extract class key from the first part\n",
    "    class_id = class_id_dict.get(class_key, parts[0].split('_')[0])  # Replace class ID using the dictionary\n",
    "    coordinates = parts[1:]  # Remaining parts are coordinates\n",
    "    # Normalize coordinates (assuming image size is known, e.g., 1024x1024)\n",
    "    image_width, image_height = 1024, 1024\n",
    "    normalized_coords = [str(float(coord) / image_width if i % 2 == 0 else float(coord) / image_height) for i, coord in enumerate(coordinates)]\n",
    "    return f\"{class_id} \" + \" \".join(normalized_coords)\n",
    "\n",
    "# Iterate over each annotation file\n",
    "for annotation_file in annotation_files:\n",
    "    input_path = os.path.join(annotation_dir, annotation_file)\n",
    "    output_path = os.path.join(output_dir, annotation_file)\n",
    "    \n",
    "    with open(input_path, 'r') as infile, open(output_path, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            converted_line = convert_annotation_line(line)\n",
    "            outfile.write(converted_line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LD_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
