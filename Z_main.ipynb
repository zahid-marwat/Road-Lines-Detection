{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "from Modules.annotator import BoxAnnotator\n",
    "\n",
    "\n",
    "videos_dir=\"Data/Raw_videos\"\n",
    "lines_model='Models/Lines_detection.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_annotator = BoxAnnotator(\n",
    "        thickness=2,\n",
    "        text_thickness=1,\n",
    "        text_scale=5\n",
    "        )\n",
    "\n",
    "\n",
    "def bounding_box_annotator(frame, filtered_zone_detections):\n",
    "    \n",
    "    # box annotator without filtering and tracking\n",
    "    # labels = [f\"{tracker_id} {model.names[class_id]}\" for _,_,_, confidence, class_id, tracker_id in filtered_zone_detections]\n",
    "    # labels = [f\"\"]\n",
    "\n",
    "    frame = box_annotator.annotate(scene=frame,\n",
    "                                   detections=filtered_zone_detections,\n",
    "                                   skip_label=False)\n",
    "    return frame\n",
    "\n",
    "def show_frames(frame):\n",
    "    cv2.imshow('Road Lines', frame)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(lines_model)  # pretrained YOLOv8n model\n",
    "\n",
    "veh_names= model.names\n",
    "\n",
    "\n",
    "def process_video(\n",
    "    video_path='Example_Videos/new videos/new4.mp4',\n",
    "    frames_dir_loc='FrameByFrame/original_Frames/',\n",
    "    results_dir_loc = 'FrameByFrame/result_Frames/'\n",
    "):\n",
    "        \n",
    "    frames_per_second = None\n",
    "\n",
    "    \n",
    "    video_name=video_path.split(os.sep)[-1]\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frames_per_second = cap.get(cv2.CAP_PROP_FPS)\n",
    "    Total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    # Check if the video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        exit()\n",
    "\n",
    "    # Create a directory to save the frames\n",
    "    os.makedirs(frames_dir_loc, exist_ok=True)\n",
    "    os.makedirs(results_dir_loc, exist_ok=True)\n",
    "    \n",
    "    # Read and save each frame\n",
    "    frame_count = 0\n",
    "    \n",
    "    for i in tqdm.tqdm(range(int(Total_frames)),\n",
    "                       desc=video_name ,\n",
    "                       bar_format=\"Processing : {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\",ascii=\"□■□■█\"):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Break the loop if the video is over\n",
    "\n",
    "        frame_count += 1\n",
    "        current_time_stamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        \n",
    "        # Run batched inference on all saved frames        \n",
    "        results = model.track(frame,agnostic_nms=True,show=False,persist=True,verbose=False)[0]  # Assuming model can handle a list of file paths\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        frame = bounding_box_annotator(frame, detections)\n",
    "        \n",
    "        show_frames(frame)\n",
    "                \n",
    "        # #turned off for now\n",
    "        cv2.imwrite(f\"{results_dir_loc}result_{frame_count:04d}.jpg\", frame)\n",
    "        if  frame_count > 2000 : break\n",
    "        \n",
    "    cap.release()\n",
    "    yolo_model_names_list = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames2video(input_folder, output_video_path, fps=30):\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
    "    image_files.sort() \n",
    "    img = cv2.imread(os.path.join(input_folder, image_files[0]))\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change the codec based on your preference\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(input_folder, image_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        video_writer.write(img)\n",
    "\n",
    "    video_writer.release()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_name= videos_dir.split(os.sep)[-1]\n",
    "videos_list = [i for i in glob.glob(videos_dir+os.sep+\"*.mp4\") ]\n",
    "\n",
    "for each_video in videos_list:\n",
    "            video_name = each_video.split(\".mp4\")[0].split(os.sep)[-1]\n",
    "            results_dir_loc='Data/Detected_videos' + video_name+'/'\n",
    "            process_video(video_path=each_video, results_dir_loc=results_dir_loc)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "frames2video(results_dir_loc, 'Data/Detected_videos' + video_name +'.mp4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob,os\n",
    "\n",
    "# Load the YOLOv8 model (replace with your specific setup)\n",
    "from ultralytics import YOLO\n",
    "lines_model='Models/Lines_detection.pt'\n",
    "model = YOLO(lines_model)\n",
    "\n",
    "# Load the image\n",
    "images_src_dir='Data/Raw_images'\n",
    "iamges_list= [i for i in glob.glob(images_src_dir+os.sep+\"*.jpg\") ]\n",
    "output_dir='Data/Detected/images'\n",
    "\n",
    "for imagefile in iamges_list:\n",
    "    image = cv2.imread(imagefile)\n",
    "    image_name=imagefile.split(os.sep)[-1]\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(image)\n",
    "\n",
    "    # Iterate through detected bounding boxes\n",
    "    for result in results[0].boxes.data:\n",
    "        x_min, y_min, x_max, y_max, confidence, class_id = result.int().tolist()\n",
    "        class_name = model.names[class_id]\n",
    "\n",
    "        # Crop the ROI\n",
    "        roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Convert ROI to HSV for color thresholding\n",
    "        hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_white = np.array([0, 0, 200])  # Adjust as needed\n",
    "        upper_white = np.array([180, 55, 255])\n",
    "\n",
    "        # Define orange color range (tweak these values for road-line orange)\n",
    "        lower_orange = np.array([15, 100, 150])  # Tighter bounds for saturation and brightness\n",
    "        upper_orange = np.array([25, 255, 255])\n",
    "        # Create masks for white and orange lines\n",
    "        mask_white = cv2.inRange(hsv_roi, lower_white, upper_white)\n",
    "        mask_orange = cv2.inRange(hsv_roi, lower_orange, upper_orange)\n",
    "\n",
    "        # Create overlay colors\n",
    "        light_green = np.array([0, 255, 0], dtype=np.uint8)  # Light green for white lines\n",
    "        light_red = np.array([0, 0, 255], dtype=np.uint8)    # Light red for orange lines\n",
    "        alpha = 0.5  # Transparency factor\n",
    "\n",
    "        # Apply green overlay for white lines\n",
    "        mask_white_3c = cv2.merge([mask_white, mask_white, mask_white])\n",
    "        roi_with_white_overlay = np.where(mask_white_3c > 0,\n",
    "                                        (alpha * light_green + (1 - alpha) * roi).astype(np.uint8),\n",
    "                                        roi)\n",
    "\n",
    "        # Apply red overlay for orange lines\n",
    "        mask_orange_3c = cv2.merge([mask_orange, mask_orange, mask_orange])\n",
    "        roi_with_overlay = np.where(mask_orange_3c > 0,\n",
    "                                    (alpha * light_red + (1 - alpha) * roi_with_white_overlay).astype(np.uint8),\n",
    "                                    roi_with_white_overlay)\n",
    "\n",
    "        # Replace the modified ROI back into the original image\n",
    "        image[y_min:y_max, x_min:x_max] = roi_with_overlay\n",
    "\n",
    "        # Overlay the class name at the top of the line\n",
    "        cv2.putText(image, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Save or display the resulting image\n",
    "    cv2.imshow('Result', image)\n",
    "    cv2.imwrite(output_dir+os.sep+image_name+'.jpg', image)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 50.4ms\n",
      "Speed: 2.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Strelka vlevo, 1 Strelka vpered, 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Strelka vpered, 38.0ms\n",
      "Speed: 3.6ms preprocess, 38.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Strelka vpered - vlevos, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Liniya 1s, 1 Strelka vpered, 1 Strelka vpered - vpravo, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Liniya 1, 1 Perehod, 49.0ms\n",
      "Speed: 0.0ms preprocess, 49.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Strelka vpered, 12.7ms\n",
      "Speed: 0.0ms preprocess, 12.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Perehods, 11.2ms\n",
      "Speed: 1.0ms preprocess, 11.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.3ms\n",
      "Speed: 0.0ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Liniya 1s, 12.3ms\n",
      "Speed: 0.0ms preprocess, 12.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Strelka vpravo, 14.2ms\n",
      "Speed: 0.0ms preprocess, 14.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Perehod, 13.2ms\n",
      "Speed: 0.0ms preprocess, 13.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Liniya 1s, 1 Strelka vpered - vlevo, 1 Strelka vpravo, 6.4ms\n",
      "Speed: 0.0ms preprocess, 6.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Perehod, 4.9ms\n",
      "Speed: 10.0ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Perehod, 16.9ms\n",
      "Speed: 0.0ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Perehod, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Liniya 1s, 2 Strelka vpereds, 13.9ms\n",
      "Speed: 0.0ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Strelka vpereds, 1 Strelka vpered - vlevo, 7.7ms\n",
      "Speed: 0.0ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Liniya 1s, 1 Perehod, 1 Strelka vpered, 1 Strelka vpered - vlevo, 15.9ms\n",
      "Speed: 0.0ms preprocess, 15.9ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 10.0ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Liniya 1s, 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob,os\n",
    "\n",
    "# Load the YOLOv8 model (replace with your specific setup)\n",
    "from ultralytics import YOLO\n",
    "lines_model='Models/Lines_detection.pt'\n",
    "model = YOLO(lines_model)\n",
    "\n",
    "# Load the image\n",
    "images_src_dir='Data/Raw_images'\n",
    "iamges_list= [i for i in glob.glob(images_src_dir+os.sep+\"*.jpg\") ]\n",
    "output_dir='Data/Detected/images'\n",
    "\n",
    "for imagefile in iamges_list:\n",
    "    image = cv2.imread(imagefile)\n",
    "    image_name=imagefile.split(os.sep)[-1]\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(image)\n",
    "\n",
    "    # Iterate through detected bounding boxes\n",
    "    for result in results[0].boxes.data:\n",
    "\n",
    "        x_min, y_min, x_max, y_max, confidence, class_id = result.int().tolist()\n",
    "        class_name = model.names[class_id]\n",
    "\n",
    "        # Crop the ROI\n",
    "        roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Convert ROI to grayscale\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        edges = cv2.Canny(blurred_roi, threshold1=50, threshold2=150)\n",
    "\n",
    "        # Find contours from edges\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a blank mask for contours\n",
    "        contour_mask = np.zeros_like(roi)\n",
    "\n",
    "        # Filter and draw contours\n",
    "        for contour in contours:\n",
    "            # Filter based on contour area or shape properties\n",
    "            if cv2.contourArea(contour) > 100:  # Minimum area threshold\n",
    "                cv2.drawContours(contour_mask, [contour], -1, (0, 255, 0), thickness=cv2.FILLED)  # Fill the contour\n",
    "\n",
    "        # Apply transparency to the mask\n",
    "        alpha = 0.5  # Transparency factor\n",
    "        roi_with_overlay = cv2.addWeighted(contour_mask, alpha, roi, 1 - alpha, 0)\n",
    "\n",
    "        # Replace the modified ROI back into the original image\n",
    "        image[y_min:y_max, x_min:x_max] = roi_with_overlay\n",
    "\n",
    "        # Overlay the class name at the top of the line\n",
    "        cv2.putText(image, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Save or display the resulting image\n",
    "    cv2.imshow('Result', image)\n",
    "    cv2.imwrite(output_dir+os.sep+image_name+'.jpg', image)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
